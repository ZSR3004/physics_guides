\documentclass{article}

\title{Discrete Math Study Guide}
\author{Ziyad Rahman \\ \href{mailto:zrahman3004@gmail.com}{zrahman3004@gmail.com}}
\date{}

\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{babel}
\usepackage{amsthm}
\usepackage{siunitx}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Logical Symbols and Deductive Reasoning}
\subsection{Variables and Statements}
A \textbf{variable} is a symbol that stands in for some specific value, be it a
person, number, etc. \\

\noindent A \textbf{statement} is a something that may evaluate to true or false.
It is usually either in the form $P$ if it does not depend on a variable
or $P(x)$ if the statement's truth depends on what the input is.

\subsection{Connective Symbols}
\subsection{Logical Laws}
\subsubsection{Associative Law}
\begin{eqnarray}
    (P \land Q) \land R &=& P \land (Q \land R) \\
    (P \lor Q) \lor R &=& P \lor (Q \lor R)
\end{eqnarray}

\subsubsection{Communative Law}
\begin{eqnarray}
    P \land Q &=& Q \land P \\
    P \lor Q &=& Q \lor P
\end{eqnarray}
\subsubsection{Distributive Law}
\begin{eqnarray}
    P \land (Q \lor R) &=& (P \land Q) \lor (P \land R) \\
    P \lor (Q \land R) &=& (P \lor Q) \land (P \lor R)
\end{eqnarray}
\subsubsection{Double Negation Law}
\begin{eqnarray}
    \neg \neg P &=& P
\end{eqnarray}
\subsubsection{De Morgan's Law}
\begin{eqnarray}
    \neg(P \land Q) &=& (\neg P \lor \neg Q) \\
    \neg(P \lor Q) &=& (\neg P \land \neg Q)
\end{eqnarray}
\subsubsection{Idempotent Law}
\begin{eqnarray}
    P \land P &=& P \\
    P \lor P &=& P
\end{eqnarray}
\subsubsection{Absorption Law}
\begin{eqnarray}
    P \land (P \lor Q) &=& P \\
    P \land (P \lor Q) &=& P 
\end{eqnarray}

\subsection{Truth Tables}
Truth tables are are relative straight forward concept. The aim is
to evaluate the truth of statement by breaking it down into its
smallest parts, then seeing if the final statement is true or false
based on the truth of the sub-statements. Here is a simple example,
\begin{center}
    \begin{tabular}{c | c | c}
        P & Q & $P \lor Q$ \\
        \hline
        T & T & T \\
        T & F & T \\
        F & T & T \\
        F & F & F \\
    \end{tabular}
\end{center}

\subsection{Tautologies and Contradictions}

\subsection{The Conditional}
\subsubsection{Definition}
The conditional can be thought of as an "if, then" statement. It 
primarily demonstrates some relationship between two statements.
In symbols, it is represented as,

\[ P \rightarrow Q \]

\noindent This statement can be read several ways in English:
\begin{enumerate}
    \item $P$ implies $Q$
    \item $P$ only if $Q$
    \item $P$ is a sufficient condition for $Q$
    \item $Q$, if $P$
    \item $Q$ is a necessary condition for $P$
\end{enumerate}

\subsubsection{The Truth of a Conditional}
We can demonstrate the truth of the conditional via a truth table.
\begin{center}
    \begin{tabular}{c | c | c}
        P & Q & $P \rightarrow Q$ \\
        \hline
        T & T & T \\
        T & F & F \\
        F & T & T \\
        F & F & T \\
    \end{tabular}
\end{center}

To put the truth table into plain words, the conditional is
true only if both $Q$ is true or if $P$ and $Q$ are both false. In other
words, the conditional is only false if only $Q$ is false.

\subsubsection{The Conditonal in Logical Connectives}
We can write the conditional in terms of basic logical connectives.
The definition of conditional in these terms is as follows.

\[ P \rightarrow Q \; \; \; \equiv \; \; \; \neg P \lor Q \; \; \; \equiv \; \; \; P \land \neg Q\]

\noindent Note that the rightmost statement is the same as the middle statement, but De Morgan's Law
was applied.

We can verify that these statements are equivalent via another truth table.

\begin{center}
    \begin{tabular}{c | c | c | c | c}
        P & Q & $P \rightarrow Q$ & $\neg P \lor Q$ & $P \land \neg Q$ \\
        \hline
        T & T & T & T & T \\
        T & F & F & F & F \\
        F & T & T & T & T \\
        F & F & T & T & T \\
    \end{tabular}
\end{center}

\subsubsection{The Converse}
The converse of a conditional is simply the conditional, but the statements
have been swapped around.
\begin{eqnarray} \nonumber
    P \rightarrow Q &\not\equiv & Q \rightarrow P
\end{eqnarray}

We could write a truth table to demonstrate that these statements are \textbf{NOT}
equivalent, but we will use the definition of the conditional (the logical symbols
version) to demonstrate intuitively that these are not the same.

\begin{eqnarray} \nonumber
    P \rightarrow Q &\equiv& \neg P \lor Q \\
    Q \rightarrow P &\equiv& \neg Q \lor P \\
    \neg P \lor Q &\not\equiv& \neg Q \lor P
\end{eqnarray}

\subsubsection{The Contrapositive}
The contrapositive of a conditional is a negated version of the original
statement. Unlike the converse of conditional, the contrapositive is 
equivalent to the original statement.
\begin{eqnarray} \nonumber
    P \rightarrow Q &\equiv& \neg Q \rightarrow P
\end{eqnarray}

We could use a truth table to show that these statements are equivalent,
but we can also use the logical forms of the conditionals achieve the same end.

\begin{eqnarray} \nonumber
    P \rightarrow Q &\equiv& \neg P \lor Q \\ \nonumber
    \neg Q \rightarrow P &\equiv& \neg \neg Q \lor \neg P \\ \nonumber
    \neg P \lor Q &\equiv& \neg \neg Q \lor P
\end{eqnarray}

\subsection{The Biconditional}
\subsubsection{Definition}
The biconditional is often read as "if an only if". It can be written in terms
of the conditional or logical connectors. It is written as follows.
\begin{eqnarray} \nonumber
    P \leftrightarrow Q
\end{eqnarray}

In terms of the conditional,
\begin{eqnarray}
    P \leftrightarrow Q  &\equiv& (P \rightarrow Q) \land (Q \rightarrow P)
\end{eqnarray}

The final definition is in terms of logical connectors.
\begin{eqnarray}
    P \leftrightarrow &\equiv& (\neg P \lor Q) \land (\neg Q \lor P)
\end{eqnarray}

\noindent Any statements that are equivalent to those above are valid definition of
the biconditional.

\subsubsection{The Truth of a Biconditional}
We can determine the truth of a biconditional via a truth table.

\begin{center}
    \begin{tabular}{c | c | c}
        P & Q & $P \leftrightarrow Q$ \\
        \hline
        T & T & T \\
        T & F & F \\
        F & T & F \\
        F & F & T \\
    \end{tabular}
\end{center}

As we can see, the biconditional only evaluates to true if (and only if) both statements
involved are true.

\subsection{Arguments}

\newpage
\section{Quantifiers}
\subsection{Introducing Quantifiers}
\textbf{The Universe of Discourse:} The set of all values that a variable can take on. It is often denoted as $\mathcal{U}$. \\

\noindent \textbf{Quantifier}: A symbol that denotes for which values in the Universe of Discourse that some statement is true for. 
There are two types.
\begin{enumerate}
    \item \textbf{Universal Quantifier}: Denoted by $\forall$. It denotes that a statement is true for all values.
    \item \textbf{Existential Quantifier}: Denoted by $\exists$. It denotes that a statement is true for some value.
\end{enumerate}

\noindent \textbf{Note:} Quantifiers only apply to immediate statements.
\begin{eqnarray} \nonumber
    \forall x (P(x) \land Q(x)) &\neq& \forall x P(x) \land \forall x Q(x) 
\end{eqnarray}

\subsubsection{Uniqueness}
$!\exists$ is a special case of the existential quantifier. It denotes that there is only
one value that satisfies the statement.

\subsubsection{Idomatic and Mathematical English}
Statements quantifiers may be translated into idiomatic or mathematical English.
The difference between the two is that idiomatic english is a translation (totally
different wording but same meaning) whereas mathematical english is a transliteration
(where you translate every part directly). \\

\noindent There are no hard and fast rules about this, but generally, you would replace the quantifier
directly with its definition and work from there. \\

\noindent For example, take the statement $\forall x \exists y (P(x) \rightarrow Q(y))$.
\begin{enumerate}
    \item \textbf{Idiomatic English:} All $x$ have some $y$.
    \item \textbf{Mathematical English:} For all $x$, there exists a $y$, such that $P(x)$ implies $Q(y)$.
\end{enumerate}

\subsection{Bound and Free Variables}
\textbf{Bound Variable:} A variable that is bound, or within the scope of, some quantifier related to it. \\
\textbf{Free Variable:} A variable that is not bound by any quantifier.

\noindent \textbf{Example:} In the statement,

\[ \forall x P(x, y) \]

x is a bound variable, while y is a free variable.

\subsection{Quantifier Negation}
Quantifiers have some negation laws associated with them. They are fairly straightforward.

\begin{eqnarray}
    \neg \forall x P(x) &\equiv& \exists x \neg P(x) \\
    \neg \exists x P(x) &\equiv& \forall x \neg P(x)
\end{eqnarray}

\section{Set Theory}
\subsection{Defining Sets}
\textbf{Set:} A collection of objects. ex. $\{0, 1, 2, 3\}$

\noindent \textbf{Object:} An element of a set. ex. $52$.
\subsubsection{Important Sets}
There are a few very important important sets that we must know. They are as follow:
\begin{eqnarray} \nonumber
    \varnothing &=& \{\} \text{; a set with no objects.} \\ \nonumber
    \mathbb{N} &=& \{x \; | \; x \text{ is a natural number}\} \\ \nonumber
    \mathbb{Z} &=& \{x \; | \; x \text{ is an integer}\} \\ \nonumber
    \mathbb{R} &=& \{x \; | \; x \text{ is a real number}\} \\ \nonumber
    \mathbb{Q} &=& \{x \; | \; x \text{ is a rational number of form } \frac{p}{q} \text{ where } p,q \in \mathbb{R} \text{ and } q \neq 0\} \\ \nonumber
    \text{Truth Set} &=& \{ x \; | \; P(x) \} \text{; the set of all objects that makes the statement true}
\end{eqnarray}

\subsection{Basic Set Operations}
\subsubsection{Intersection}
The intersection of two sets is the set of elements in both sets.
\begin{eqnarray}
    A \cup B = \{x \; | \; x \in A \land x \in B\}
\end{eqnarray}

\subsubsection{Union}
The union of two sets is the set of all elements in the sets.
\begin{eqnarray}
    A \cap B = \{ x \; | \; x \in A \lor x \in B \}
\end{eqnarray}

\subsubsection{Difference}
The difference of two sets is the set of elements in the first but not the second.
\begin{eqnarray}
    A \backslash B = \{ x \; | \; x \in A \land x \notin B \}
\end{eqnarray}

\subsubsection{Symmetric Difference}
The symmetric difference of two sets is the set of all elements not in 
their intersection.
\begin{eqnarray}
    A \triangle B = \{ x \; | \; (A \backslash B) \cup (B \backslash A)\} = \{ x \; | \; (A \cup B) \backslash (A \cap B) \}
\end{eqnarray}

\subsubsection{Subsets, Proper and Improper}
An (improper) subset is when all elements in some set is contained in some
other set. \\
\begin{eqnarray}
    A \subseteq B &=& \{ x \; | \; \forall x(x \in A \rightarrow x \in B) \}
\end{eqnarray}

\noindent A proper subset is when all elements in some set are equal to all elements of
another set.
\begin{eqnarray}
    A \subset B &=& \{ x \; | \; \forall x(x \in A \leftrightarrow x \in B) \}
\end{eqnarray}

\subsection{Families of Sets}
\textbf{Family of Sets:} Any set that is a set of sets, often denoted as $\mathcal{F}$. For example,
\begin{eqnarray} \nonumber
    \mathcal{F} = \{A, B, C\} = \{\{1, 2, 3\}, \{4, 5, 6\}, \{5, 6, 7\}\}
\end{eqnarray}

\subsubsection{Index Sets}
\textbf{Index Set:} A set that indexes another set. \\

\noindent An index set does not need to be strictly consecutive integers. For example,
both of the following sets are valid index sets.
\begin{eqnarray} \nonumber
    I &=& \{1, 2, 3\} \\ \nonumber
    J &=& \{3, 42, 54\}
\end{eqnarray}

\noindent \textbf{Indexed Set:} A family of sets that has been indexed by an indexed set.
It is often defined as the following.
\begin{eqnarray}
    \mathcal{A} &=& \{A_i \; | \; i \in I\}
\end{eqnarray}

\subsubsection{The Power Set}
\textbf{Power Set:} A set whose elements are all subsets of some other set.
\begin{eqnarray}
    \mathcal{P}(A) &=& \{ S \; | \; S \subseteq  A \}
\end{eqnarray}

\noindent Example:
\begin{eqnarray} \nonumber
    A &=& \{ 1, 2 \} \\ \nonumber
    \mathcal{P}(x) &=& \{ \{1\}, \{2\}, \{1, 2\}, \varnothing \}
\end{eqnarray}

% Need to check these definitions !
\subsubsection{Operations on Families of Sets}
\textbf{Intersection of Sets:} A set of all elements that are common to all the sets
in the family.
\begin{eqnarray}
    \bigcap \mathcal{F} &=& \{ x \; | \; \forall A \in \mathcal{F}(x \in A) \}
\end{eqnarray}

\noindent Another way to think about the intersection of sets is as follows.
\[ A_1 \cap A_2 \cap ... \cap A_i \]

\noindent \textbf{Union of Sets:} A set of all elements that are in all the sets
in the family.
\begin{eqnarray}
    \bigcup \mathcal{F} &=& \{ x \; | \; \exists A \in \mathcal{F}(x \in A) \}
\end{eqnarray}

\noindent Another way to think about the intersection of sets is as follows.
\[ A_1 \cup A_2 \cup ... \cup A_i \]

\section{Proof Strategies}
\subsection{Theorems, Propositions, and Lemmas}
\textbf{Theorems, Propositions, or Lemma}: If certain conditions called hypotheses,
premises, or givens are true, then their conclusions are true. The difference between
each of these is simply how important they are; theorems are the most important and 
lemmas are the least important. \\

\noindent \textbf{Proof:} Chain of mathematical statements, where each claim is fully
justified using the hypotheses, logical axioms, something you have already proven, and
basic arithmetic until a conclusion is reached. \\

\noindent All proofs have the following structure:
\begin{theorem}
    Assumptions and a statement to be proven, say $P \rightarrow Q$.
\end{theorem}
\begin{proof}
    A series of logical steps that lead to the conclusion.
    Thus, $Q$ holds. Therefore, $P \rightarrow Q$.
\end{proof}

\subsection{Proof Writing Basics}
To prove a statement, you must prove that \textit{all} instances
are true, not just one. You must somehow show that for all inputs of the variable (within
the bounds of our assumptions) to statement holds true. If there is even one instance where
the statement evaluates to false, the statement false. \\ 

\noindent There is no algorithm for proving a statement. There are a few key proof strategies
that can help guide your thinking, but ultimately it takes trial and error. Proof writing
typically occur in two stages.
\begin{enumerate}
    \item Scratch work: This is the trial and error stage where you try all the proof strategies.
    in this stage, you may make use of any logical symbols you need to.
    \item Final proof: This is when you formally write your proof. You should keep symbols like
    quantifiers to a minimum, and write in plain English.
\end{enumerate}

\noindent During the scratch work stage, it's often suggested to organize your work into a given and goal
column. The given is everything you are assuming about the problem and the goal column is what you
are actually trying to prove. \\

\noindent \textbf{Example:}
\begin{lemma}
    Suppose $x \in \mathbb{R}$ and $x > 0$. If $x^2 < 1$, then $x < 1$.
\end{lemma}
\textit{Scratch work:}
\begin{center}
\begin{tabular}{c | c}
    Given & Goal \\
    \hline
    $x \in \mathbb{R}$ & $(x^2 < 1) \rightarrow (x < 1)$ \\
    $x > 0$ & \\
\end{tabular}
\end{center}

\subsection{General Proof Strategies}

\subsubsection{Direct Proofs}
Direct proofs are the simplest form of proof. Often times, we will use other methods to 
make a statement easier to prove, so that we can use a direct proof on it. \\

\noindent Direct proofs will often take the following form.
\begin{theorem}
    $P \rightarrow Q$
\end{theorem}
\begin{proof}
    Assume that $P$ is true. [Arguments using logical laws, definitions, and basic arithmetic].
\end{proof}

\subsubsection{Proof by Contrapositive}
Proof by contrapositive takes that statement that needs to be proven, then applies the
conditional contrapositive law to it. The idea is, if you can prove the contrapositive
of the statement, you can prove the original statement because the contrapositive and the
original statement are equivalent. \\

\noindent Contrapositive proofs will often take the following form.
\begin{theorem}
    $P \rightarrow Q$
\end{theorem}
\begin{proof}
    We will argue this theorem by using the contrapositive. Suppose $\neg Q$. [A direct proof on
    $\neg Q \rightarrow P$]. Thus, $\neg P$. Therefore, by the contrapositive law, $P \rightarrow Q$. 
\end{proof}

\subsubsection{Proof by Contradiction}
A proof by contradiction requires you take all assumptions and prove the opposite of your conclusion. Then, you show that there must be some 
contradiction that arises from these assumptions.

\noindent Contradiction proofs usually take the following form.
\begin{lemma}
    $P \rightarrow Q$
\end{lemma}
\begin{proof}
    We will argue this lemma via proof by contradiction. Suppose $P$. Further, assume towards a contradiction that $\neg Q$. [Show how there
    is some contradiction that arises from these assumptions]. However, this proves a contradiction because [explain what the exact 
    contradiction is]. Therefore, if $P$ then $Q$.
\end{proof}

\noindent This type of proof is often useful for when the conclusion we are seeking is a negative statement (that is $\neg P$). Then you can just assume
the statement (that is $P$) and just find a contradiction.

If you have a given in the form $P \rightarrow Q$, there are two rules we can apply:
    \begin{enumerate}
        \item \textit{Modus Ponens}: If you know $P$ and $P \rightarrow Q$ are true, then $Q$ is true.
        \item \textit{Modus Tolen}: If you know $P \rightarrow Q$ is true but $Q$ is false, then $P$ must also be false.
    \end{enumerate}

\subsubsection{For all Proofs}
If you have a proof with the universal quantifier, you present an "arbitrary" variable that is bound to it.

\begin{lemma}
    For all $x$, $P(x) \rightarrow Q(x)$.
\end{lemma}
\begin{proof}
    Let $x$ be arbitrary. [Proof of $P(x)$]. Since $x$ was arbitrary, for all $x$, $P(x) \rightarrow Q(x)$.
\end{proof}

\noindent If you have a given that uses the universal quantifier, you can simply \textit{universal instantiation}. Just introduce an arbitrary
value such that that given is true.

\subsubsection{There Exists Proofs}
For proofs with the existence quantifier, you will find a value that satisfies the claim, then present it in the proof by saying let $x = $ that value.

\begin{lemma}
    There exists an $x$ such that $P(x) \rightarrow Q$.
\end{lemma}
\begin{proof}
    Let $x =$ the value you found in your scratch work. [Proof of $P(x) \rightarrow Q(x)$]. Thus, there exists an $x = $ that value such that
    $P(x) \rightarrow Q(x)$.
\end{proof}

\noindent To use a given in the form of $\exists xP(x)$, we can use a strategy called \textit{existential instantiation}. To do this, you introduce a variable
$x_0$ such that $P(x_0)$ is true. Thus, you can assume $P(x_0)$ for your givens.

\begin{lemma}
    Suppose $P(x)$ is true for specific values. Then, show $P(x) \rightarrow Q(x)$.
\end{lemma}
\begin{proof}
    Suppose there exists $x_0$ such that $P(x_0)$ is true. [Proof of $P(x_0) \rightarrow Q(x_0)$].
\end{proof}

\subsubsection{There Exists a UNIQUE Proofs}
To prove uniqueness, you must show that there exists a value to satisfy the claim, then show that there is only one value to satisfy it. You can split
this into two parts. First, prove existence using the there existence proof strategies. Then, to show uniqueness you can do one of two things:
\begin{enumerate}
    \item Assume two values satisfy the claim, then show that these values are in fact equal to each other. In logical symbols, we are proving the 
            following.
            \begin{eqnarray*}
                \forall x \forall y (P(x) \land P(y) \rightarrow x = y)
            \end{eqnarray*}
    \item Slightly more involved, but given the assumptions, prove that one value that can fulfill all necessary traits.
\end{enumerate} 

\subsection{Proofs Involving Conjunctions and Biconditionals}
\subsubsection{Conjunction Proofs}
\textbf{Conjunction}: A statement of the form $P \land Q$.
For these proofs, you can use any of the proof strategies; however, you should do it in two parts: first prove $P$, then prove $Q$.

\begin{lemma}
    $P \land Q$
\end{lemma}
\begin{proof}
    We will prove this proof in two parts. First, we will prove $P$, then we will prove $Q$.
    [Proof of $P$].
    [Proof of $Q$].
    Having proven $P$ and $Q$, we have completed this proof.
\end{proof}

\subsubsection{Biconditional Proofs}
To prove a biconditional, we can use the fact that,
\begin{eqnarray*}
    P \leftrightarrow Q \equiv (P \rightarrow Q) \land (Q \rightarrow P)
\end{eqnarray*}

\noindent Then, this becomes a conjunction problem, so we prove $P \rightarrow Q$, then prove $Q \rightarrow P$.

\noindent There is a "special" case for biconditional proofs. It hinges off the following definition.
\begin{eqnarray*}
    P = Q \equiv (P \subset Q) \land (Q \subset P)
\end{eqnarray*}

\noindent From here, we can again use conjunction. This case is called \textbf{double containment}. \textbf{Containment} is just showing that
some set is a subset of another set. So, double containment is just showing two cases of subsets, specific that the first set is a subset of the
second set and vice versa.

\subsection{Proofs Involving Disjunctions}
\textbf{Disjunction}: A statement in the form $P \lor Q$. \\

\noindent For a disjunction proof, prove the first case, then the second case. For a goal of $P \lor Q$, prove $P$ then $Q$. For a given of that form, prove your goal first by only assuming $P$ then only
assuming $Q$.

\section{Relations}
\subsection{Ordered Pairs and Cartesian Products}
\textbf{Ordered pairs} are of the form $(x,y)$ and hold possible values for each variable. As the name suggests, the order in which they are in matters,
i.e. $(x,y)$ is different from $(y,x)$. \\

\noindent The \textbf{cartesian product} is the set of all ordered pairs such that the first element is in some set $A$ and the second element is in
another set $B$. More formally,
\begin{eqnarray*}
    A \times B = \{ (a,b) \; | \; a \in A \land b \in B \}.
\end{eqnarray*}

\subsection{Relations}
Suppose $A$ and $B$ are sets. A \textbf{relation} $R$ from $A$ to $B$ is defined as,
\begin{eqnarray*}
    R \subseteq A \times B.
\end{eqnarray*}

\noindent There are a few ways to denote a relation. The most common is perhaps $(a,b) \in R$, but you may see other notation such as $xRy$ as well.

\noindent Similar to functions, relations have a \textbf{domain} and \textbf{range}.
\begin{eqnarray*}
    Dom(R) &=& \{ a \in A \; | \; \exists b \in B ((a,b) \in R) \} \\
    Ran(R) &=& \{ b \in B \; | \; \exists a \in A ((a, b) \in R) \}.
\end{eqnarray*}

\noindent The \textbf{inverse} of $R$ is defined as,
\begin{eqnarray*}
    R^{-1} &=& \{ (b,a) \in B \times A \; | \; (a,b) \in R \}.
\end{eqnarray*}

\noindent Last, we consider set composition. Suppose there are three sets $A$, $B$, $C$ and $R$ is a relation from $A$ to $B$ and $S$ is a relation
from $B$ to $C$. We can define a composition of $S$ and $R$ as,
\begin{eqnarray*}
    S \circ R &=& \{ (a,c) \in A \times C \; | \; \exists b \in B ((a, b) \in R \land (b, c) \in S) \}.
\end{eqnarray*}

\subsection{Equivalence Relations}
\subsubsection{A Primer}
Equivalence relations are a special, very important subset of the cartesian product. Before explaining exactly what this set looks like, we 
must understand a few possible traits of a relation. Not all sets follow these characteristics, but relations that have the following constructions
have special names. Thus, the three most important types.
\begin{eqnarray*}
    \text{Reflexive} &=& \forall x \in A ((x,x) \in R) \\
    \text{Symmetric} &=&  \forall x,y \in A((x,y) \in R \rightarrow (y,x) \in R) \\
    \text{Transitive} &=& \forall x,y,z \in A(((x,y), (y,z) \in R) \rightarrow (x,z) \in R).
\end{eqnarray*}

\noindent There is another definition we will cover for a closely related type of set. A \textbf{pairwise disjoint} set is one such that
\begin{eqnarray*}
    \forall X, Y \in \mathcal{F}(X \neq Y \rightarrow X \cap Y = \varnothing).
\end{eqnarray*}

\subsubsection{Equivalence Relations and Classes}
\textbf{Equivalence relations} are a subset of the cartesian product such that this set is reflexive, symmetric, and transitive. \\

\noindent Let $R$ be an equivalence relation on a set $A$. Let $x \in A$. The \textbf{equivalence class} of $x$ with respect to $R$ is the set
denoted by $[x]_R$ is defined by
\begin{eqnarray*}
    [x]_R &=& \{ y \in A \; | \; (x,y) \in R \}.
\end{eqnarray*}

\noindent The set of all equivalence classes of $A$ with respect to $R$ is called $A$ modulo $R$ and is denoted $A / R$. That is,
\begin{eqnarray*}
    A / R &=& \{ [x]_R \; | \; x \in A \}.
\end{eqnarray*}

\subsubsection{Partition of Sets}
Let $A$ be a set and $\mathcal{F} \subseteq \mathcal{P}(A)$ (i.e. $\mathcal{F}$ is a subset of the subsets of $A$). Then, $\mathcal{F}$ is a
partition of $A$ if the following properties hold:
\begin{enumerate}
    \item $\forall X \in \mathcal{F}, X \neq \varnothing$.
    \item $\bigcup \mathcal{F} = A$.
    \item $\mathcal{F}$ is pairwise disjoint.
\end{enumerate}

\subsubsection{The Fundamental Theorem of Equivalence Relations}
There is a very important theorem related to equivalence relations and partitions. The theorems and related lemmas are written below. The
proofs themselves are left as an excercise to the reader. \\

\begin{lemma} \label{eq_relate_lemma_A}
    Suppose $R$ is an equivalence relation on set $A$. Then, for all $x \in A$, $x \in [x]_R$.
\end{lemma}

\begin{lemma} \label{eq_relate_lemma_B}
    Suppose $R$ is a relation on $A$. Then, for all $x \in A$ and $y \in A$, $y \in [x]_R$ if and only if $[y] =[x]$.
\end{lemma}

\begin{theorem} \label{eq_relate_theorem_1}
    Suppose $R$ is an equivalence relation on a set $A$. Then, $A / R$ is a partition of $A$. 
\end{theorem}

\begin{lemma} \label{eq_relate_lemma_1}
    Suppose $A$ is a set and $\mathcal{F}$ is a partition on $A$. Let,
    \begin{eqnarray*}
        R &=& \bigcup_{X \in \mathcal{F}} (X \times X).
    \end{eqnarray*}
\end{lemma}

\begin{lemma} \label{eq_relate_lemma_2}
    Suppose $A$ is a set $\mathcal{F}$ is a partition on $A$. Let $R$ be the equivalence relation determined by $\mathcal{F}$ (given in lemma 
    \ref{eq_relate_lemma_1}). Suppose $X \in \mathcal{F}$ and $x \in X$. Then $[x]_R = X$.
\end{lemma}

\begin{theorem} \label{eq_relate_theorem_2}
    Suppose $A$ is a set and $\mathcal{F}$ is partition of $A$. Then, there exists an equivalence relation $R$ on $A$ so that $A / R = \mathcal{F}$.
\end{theorem}

\noindent \textit{Commentary.} Use \textit{lemma \ref{eq_relate_lemma_A}} and \textit{lemma \ref{eq_relate_lemma_B}} to prove 
\textit{theorem \ref{eq_relate_theorem_1}.} Use \textit{lemma \ref{eq_relate_lemma_1}} and \textit{lemma \ref{eq_relate_lemma_2}} to prove 
\textit{theorem \ref{eq_relate_theorem_2}}.

\section{Functions}
\subsection{Defining Functions}
A \textbf{function} is another type of subset of the cartesian product. Like equivalence relations, a set is only considered a function if it meets 
certain criteria. The formal definition is as follows.

\noindent Let $A$ and $B$ be sets. A function from $A$ to $B$ is a relation $F$ from $A$ to $B$ (so, $F \subseteq A \times B$), so that for all
$a \in A$, there exists a unique element $b \in B$ so that $(a,b) \in F$. We can also write this in logical symbols as
\begin{eqnarray*}
    \forall x \in A ( \exists ! y \in B((a,b) \in F)).
\end{eqnarray*}

\noindent \textbf{Notation.} If $F$ is a function from $A$ to $B$, then we can write it as $F: A \rightarrow B$. If $a \in A$ and $(a,b) \in F$ for a unique
$b \in B$, then you can denote the value of $F$ at $a$ as $F(a)$. You can also write this as the image of $F$ at $a$ or $F$ of $a$.

\subsubsection{Domain and Range}
Let $F: A \rightarrow B$. Then,
\begin{eqnarray*}
    Dom(F) &=& A \\
    Ran(F) &=& \{ F(a) \; | \; a \in A \}
\end{eqnarray*}

\subsubsection{Composition}
Let $f : A \rightarrow B$ and $g: B \rightarrow C$. Then, $f \subseteq A \times B$ and $g \subseteq B \times C$. So,
\begin{eqnarray*}
    g \circ f \subseteq A \times C.
\end{eqnarray*}

\noindent Which can be more explicitly defined by
\begin{eqnarray*}
    g \circ f &=& \{ (a,c) \; | \; \exists b \in B ((a,b) \in f \land (b,c) \in g) \}.
\end{eqnarray*}

\noindent We can also write the image of $g$ of $f$ on $a$ by
\begin{eqnarray*}
    (g \circ f)(a) = c = g(b) = g(f(a)).
\end{eqnarray*}

\subsection{Injective, Surjective, and Bijective}
\subsubsection{Injective or One-to-One}
Let $f: A \rightarrow B$. $f$ is \textbf{injective/one-to-one/1-1} if it can be defined by one of the following,
\begin{eqnarray*}
    \forall a_1, a_2 \in A (f(a_1) = f(a_2) \rightarrow a_1 = a_2) \\
    \forall a_1, a_2 \in A(a_1 \neq a_2 \rightarrow f(a_1) \neq f(a_2)).
\end{eqnarray*}

\subsubsection{Surjective or Onto}
Let $f: A \rightarrow B$. $f$ is \textbf{surjective/onto} if it can be defined by one of the following.
\begin{eqnarray*}
    \forall b \in B \exists a \in A(f(a) = b) \\
    Ran(f) = B.
\end{eqnarray*}

\subsubsection{Bijective}
A function is \textbf{Bijective} if it is injective and surjective. In logical form:
\begin{eqnarray*}
    (\forall a_1, a_2 \in A (f(a_1) = f(a_2) \rightarrow a_1 = a_2)) \land (\forall b \in B \exists a \in A(f(a) = b)),
\end{eqnarray*}
\noindent or by using any of the equivalent equations defined above.

\subsection{Inverse Functions}


\subsection{Closures}

\section{Mathematical Induction}
\subsection{Proof by Induction}
\subsection{Recursion}
\subsection{Strong Induction}
\subsection{Closures Part II}

\section{Number Theory}
\subsection{Greatest Common Divisor}
\subsection{Prime Factorization}
\subsection{Modular Arithmetic}
\subsection{Euler's Theorem}
\subsection{Public-Key Cryptography}

\section{Infinite Sets}
\subsection{Equinumerous Sets}
\subsection{Countable and Uncountable Sets}
\subsection{The Cantor-Schröder-Bernstein Theorem}

\end{document}